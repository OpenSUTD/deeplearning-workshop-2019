{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Lab 1: Loading and Displaying Data\n",
    "\n",
    "### Dataset `readme.txt`\n",
    "\n",
    "(formatted slightly nicer for sanity)\n",
    "\n",
    "**Captions, Dataset Splits, and Human Annotations**\n",
    "\n",
    "* `Flickr8k.token.txt` - the raw captions of the Flickr8k Dataset . The first column is the ID of the caption which is `image address # caption number`\n",
    "* `Flickr8k.lemma.txt` - the [lemmatized](https://en.wikipedia.org/wiki/Lemmatisation) version of the above captions \n",
    "* `Flickr_8k.trainImages.txt` - The training images used in our experiments\n",
    "* `Flickr_8k.devImages.txt` - The development/validation images used in our experiments\n",
    "* `Flickr_8k.testImages.txt` - The test images used in our experiments\n",
    "\n",
    "\n",
    "**`ExpertAnnotations.txt` is the expert judgments**\n",
    "\n",
    "* The first two columns are the image and caption IDs.\n",
    "* Caption IDs are `<image file name>#<0-4>`.\n",
    "* The next three columns are the expert judgments for that image-caption pair.\n",
    "* Scores range from 1 to 4:\n",
    "* 1 indicating that the caption does not describe the image at all, a 2 indicating the caption describes minor aspects of the image but does not describe the image, a 3 indicating that the caption almost describes the image with minor mistakes, and a 4 indicating that the caption describes the image.\n",
    "\n",
    "\n",
    "**`CrowdFlowerAnnotations.txt` contains the CrowdFlower judgments**\n",
    "\n",
    "* The first two columns are the image and caption IDs.\n",
    "* The third column is the percent of Yes, the fourth column is the total number of Yes, the fifth column is the total number of No.\n",
    "* A Yes means that the caption describes the image (possibly with minor mistakes), while a No means that the caption does not describe the image.\n",
    "* Each image-caption pair has a minimum of three judgments, but some may have more.\n",
    "\n",
    "```\n",
    "If you use this corpus / data:\n",
    "Please cite: M. Hodosh, P. Young and J. Hockenmaier (2013) \"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics\", Journal of Artifical Intellegence Research, Volume 47, pages 853-899\n",
    "http://www.jair.org/papers/paper3994.html\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def print_long_list(long_list):\n",
    "    \"\"\"\n",
    "    Prints the start, middle, and end of a long list\n",
    "    \"\"\"\n",
    "    midpoint = int(len(long_list)/2)\n",
    "    print(long_list[0])\n",
    "    print(long_list[1])\n",
    "    print(\"...\")\n",
    "    print(long_list[midpoint-1])\n",
    "    print(long_list[midpoint])\n",
    "    print(\"...\")\n",
    "    print(long_list[-2])\n",
    "    print(long_list[-1], \"; total =\", len(long_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you had the images in a folder, you would load them this way\n",
    "# however, today we're going to twist things and make things harder\n",
    "\n",
    "\"\"\"\n",
    "import glob\n",
    "\n",
    "IMAGES_DIR = \"./flickr8k/images\"\n",
    "image_paths = glob.glob(IMAGES_DIR+\"/*.jpg\")\n",
    "image_paths.sort()\n",
    "print_long_list(image_paths)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load Annotations and Captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A: Loading Annotations**\n",
    "\n",
    "The annotations mark the quality of the captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_good_expert_annotations(FILE_PATH):\n",
    "    \"\"\"\n",
    "    Only load the annotations that all experts gave 3 or better\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        annotations = csv.reader(f, delimiter='\\t')\n",
    "        for row in annotations:\n",
    "            scores = [int(row[2]), int(row[3]), int(row[4])]\n",
    "            if min(scores)>2:\n",
    "                # all scores are 3 or better\n",
    "                output.append(row[:2])\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_good_crowd_annotations(FILE_PATH, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Only load the annotations that crowd-sourced \"Yes\" response > threshold\n",
    "    Where threshold: 0 <= threshold <= 1; 0.5 = 50%\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        annotations = csv.reader(f, delimiter='\\t')\n",
    "        # answer start\n",
    "\n",
    "        # answer end\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra tip unrelated to this exercise**\n",
    "\n",
    "Sometimes the first row is a header (aka the column titles). We could skip a row by using `next(annotations)` since `annotations` is a iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_ann = load_good_expert_annotations(\"./flickr8k/captions/ExpertAnnotations.txt\")\n",
    "print_long_list(expert_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "```\n",
    "['1107246521_d16a476380.jpg', '3582742297_1daa29968e.jpg#2']\n",
    "['1119015538_e8e796281e.jpg', '229862312_1a0ba19dab.jpg#2']\n",
    "...\n",
    "['3085667865_fa001816be.jpg', '3631986552_944ea208fc.jpg#2']\n",
    "['309687244_4bdf3b591f.jpg', '197107117_4b438b1872.jpg#2']\n",
    "...\n",
    "['925491651_57df3a5b36.jpg', '925491651_57df3a5b36.jpg#2']\n",
    "['997722733_0cb5439472.jpg', '486917990_72bd4069af.jpg#2'] ; total = 593\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_ann = load_good_crowd_annotations(\"./flickr8k/captions/CrowdFlowerAnnotations.txt\")\n",
    "print_long_list(crowd_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "```\n",
    "['1056338697_4f7d7ce270.jpg', '1056338697_4f7d7ce270.jpg#2']\n",
    "['1056338697_4f7d7ce270.jpg', '524105255_b346f288be.jpg#2']\n",
    "...\n",
    "['3080056515_3013830309.jpg', '3080056515_3013830309.jpg#2']\n",
    "['308487515_7852928f90.jpg', '308487515_7852928f90.jpg#2']\n",
    "...\n",
    "['968081289_cdba83ce2e.jpg', '968081289_cdba83ce2e.jpg#2']\n",
    "['997722733_0cb5439472.jpg', '872622575_ba1d3632cc.jpg#2'] ; total = 1323\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B: Loading Captions**\n",
    "\n",
    "Each image has a few associated captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_captions_to_list(FILE_PATH):\n",
    "    output = []\n",
    "    for line in open(FILE_PATH, 'r'):\n",
    "        line = line.split(\"\\t\")\n",
    "        # answer start\n",
    "        \n",
    "        # answer end\n",
    "        output.append([image, caption])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_list = load_captions_to_list(\"./flickr8k/captions/Flickr8k.token.txt\")\n",
    "print_long_list(captions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "```\n",
    "['1000268201_693b08cb0e.jpg#0', 'a child in a pink dress is climbing up a set of stairs in an entry way .']\n",
    "['1000268201_693b08cb0e.jpg#1', 'a girl going into a wooden building .']\n",
    "...\n",
    "['3106223494_52d4d2d75d.jpg#4', 'guy in santa suit wearing ninja mask and horns']\n",
    "['3106340185_80d0cb770a.jpg#0', 'a man takes a picture out a window .']\n",
    "...\n",
    "['997722733_0cb5439472.jpg#3', 'a rock climber in a red shirt .']\n",
    "['997722733_0cb5439472.jpg#4', 'a rock climber practices on a rock climbing wall .'] ; total = 40460\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def list_to_dict(list_):\n",
    "    output = {}\n",
    "    for item in list_:\n",
    "        output[item[0]] = item[1]\n",
    "    return output\n",
    "\n",
    "def get_random_key(dictionary):\n",
    "    total_num = len(dictionary.keys())\n",
    "    rand_num = random.randint(0, total_num)\n",
    "    rand_key = list(dictionary.keys())[rand_num]\n",
    "    return rand_key\n",
    "\n",
    "def print_rand_example(dictionary):\n",
    "    rand_key = get_random_key(dictionary)\n",
    "    rand_caption = dictionary[rand_key]\n",
    "    print(\"Image:  \", rand_key.split(\"#\")[0])\n",
    "    print(\"Caption:\", rand_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = list_to_dict(captions_list)\n",
    "print_rand_example(captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Display Images and Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from requests import get\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "def make_folder(path):\n",
    "    \"\"\"\n",
    "    Create a directory (folder) unless it already exists.\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "def download_image_file(image_id, output_path):\n",
    "    BASE_URL = \"https://tlkh.design/downloads/flickr8k/images/\"\n",
    "    \n",
    "    with open(output_path, \"wb\") as file:\n",
    "        response = get(BASE_URL+image_id)\n",
    "        file.write(response.content)\n",
    "        \n",
    "    return output_path\n",
    "\n",
    "def display_rand_image(key):\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    OUTPUT_FOLDER = \"./flickr8k/images/\"\n",
    "    \n",
    "    make_folder(OUTPUT_FOLDER)\n",
    "    \n",
    "    image_id = key.split(\"#\")[0]\n",
    "    image_path = download_image_file(image_id, OUTPUT_FOLDER+image_id)\n",
    "    \n",
    "    possible_caption_key = [image_id+\"#\"+str(i) for i in range(5)]\n",
    "    \n",
    "    label = \"\"\n",
    "    \n",
    "    for key in possible_caption_key:\n",
    "        try:\n",
    "            caption = captions[key]\n",
    "            label += \"\\n\"+caption\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "    x, y = int(image.shape[1]*1.1), int(image.shape[0]*0.5)\n",
    "    plt.text(x, y, label, verticalalignment='top')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    plt.figure(i)\n",
    "    plt.title(\"Picture \"+str(i))\n",
    "    display_rand_image(get_random_key(captions))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data):\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # distribution of text lengths\n",
    "    lengths = np.array([len(row[1].split(\" \")) for row in data])\n",
    "    summary = \"mean: \"+str(int(np.mean(lengths)))+\" , min/max: \"+str(np.min(lengths))+\"/\"+str(np.max(lengths))+\" (95%: \"+ str(round(np.percentile(lengths, 95), 2)) + \")\"\n",
    "    plt.figure(1, figsize=(10,6))\n",
    "    plt.hist(lengths, bins='auto')\n",
    "    plt.title(\"Distribution of text lengths\")\n",
    "    plt.xlabel(\"Text Length: \" + summary); plt.ylabel(\"Examples\")\n",
    "    plt.axvline(np.mean(lengths), ls=\"-\", color=\"k\")\n",
    "    plt.axvline(np.percentile(lengths, 95), ls=\"--\", color=\"k\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(captions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
