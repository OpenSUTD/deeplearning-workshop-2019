{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Lab 4C - Transfer Learning in NLP\n",
    "\n",
    "## Fine-tuning ELMo for Text Classification\n",
    "\n",
    "In this Code Lab, we are going to make use of a pre-trained ELMo model from [TensorFlow Hub](https://www.tensorflow.org/hub/). ELMo is a model that makes use of a **language model** (a more complex representation compared to word embeddings) to achieve state of the art results (until recently, but that's how fast things are moving.\n",
    "\n",
    "**More on ELMo**\n",
    "\n",
    "* https://allennlp.org/elmo\n",
    "* [ArXiv: Deep contextualized word representations](https://arxiv.org/abs/1802.05365)\n",
    "\n",
    "This notebook consist of 4 main sections:\n",
    "\n",
    "1. Preparing the data\n",
    "2. Implementing a simple CNN model\n",
    "3. Training the model\n",
    "4. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Model Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 100000    # max no. of words for tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 20 # max length of each entry (sentence), including padding\n",
    "VALIDATION_SPLIT = 0.3   # data for validation (not used in training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re, sys, csv, pickle\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras import regularizers, initializers, optimizers, callbacks\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Step**\n",
    "\n",
    "Removing [stopwords](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html), punctuation and making everything lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def clean_text(text, remove_stopwords=True):\n",
    "    output = \"\"\n",
    "    text = str(text).replace(\"\\n\", \"\")\n",
    "    text = re.sub(r'[^\\w\\s]','',text).lower()\n",
    "    if remove_stopwords:\n",
    "        text = text.split(\" \")\n",
    "        for word in text:\n",
    "            if word not in stopwords.words(\"english\"):\n",
    "                output = output + \" \" + word\n",
    "    else:\n",
    "        output = text\n",
    "    return str(output.strip())[1:-3].replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading from Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31382c724d7647659651ccad0155e1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = []   # empty list for model input: the movie reviews\n",
    "labels = []  # empty lists model output: sentiment labels\n",
    "\n",
    "data_neg = open(\"datasets/stanford_movie_neg.txt\", \"rb\") \n",
    "for line in tqdm_notebook(data_neg, total=5331): \n",
    "    texts.append(clean_text(line, remove_stopwords=False))\n",
    "    labels.append(int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb230da1aee487d82ce4bbd5ad03382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_pos = open(\"datasets/stanford_movie_pos.txt\", \"rb\") \n",
    "for line in tqdm_notebook(data_pos, total=5331): \n",
    "    texts.append(clean_text(line, remove_stopwords=False))\n",
    "    labels.append(int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample negative: simplistic silly and tedious 0\n",
      "Sample positive: with few respites marshall keeps the energy humming and his edits unlike those in moulin rouge are crisp and purposeful without overdoing it 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample negative:\", texts[0], labels[0])\n",
    "print(\"Sample positive:\", texts[9000], labels[9000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate the array of sentences from dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Shape of data tensor: (10662, 1)\n",
      "[i] Shape of label tensor: (10662, 2)\n",
      "[i] Number of entries in each category:\n",
      "[+] Training: [3709. 3755.]\n",
      "[+] Validation: [1622. 1576.]\n"
     ]
    }
   ],
   "source": [
    "all_text = [' '.join(t.split()[0:150]) for t in texts]\n",
    "all_text = np.array(all_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "labels = to_categorical(np.asarray(labels)) # convert the category label to one-hot encoding\n",
    "print('[i] Shape of data tensor:', all_text.shape)\n",
    "print('[i] Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(all_text.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "all_text = all_text[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * all_text.shape[0])\n",
    "x_train = all_text[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = all_text[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "print('[i] Number of entries in each category:')\n",
    "print(\"[+] Training:\",y_train.sum(axis=0))\n",
    "print(\"[+] Validation:\",y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does the data look like?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence input ['the pleasure of read my lips is like seeing a series of perfect black pearls clicking together to form a string were drawn in by the dark luster']\n",
      "\n",
      "One-hot label [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence input\", all_text[0])\n",
    "print(\"\")\n",
    "print(\"One-hot label\", labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the model\n",
    "\n",
    "We will now start to create the model in `Keras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the `ELMo` layer**\n",
    "\n",
    "Computes deep contextualized word representations using character-based word representations and bidirectional LSTMs. Paper: [Deep contextualized word representations](https://arxiv.org/abs/1802.05365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloaded https://tfhub.dev/google/elmo/2, Total size: 357.40MB\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    }
   ],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())\n",
    "\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rest of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(1,), dtype=tf.string)\n",
    "embedded_sequences = Lambda(ElmoEmbedding, output_shape=(1024,))(sequence_input)\n",
    "embedded_sequences = Reshape((1024, 1,))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_drop = Dropout(0.5)(embedded_sequences)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(32, activation='relu')(l_flat)\n",
    "preds = Dense(2, activation='softmax')(l_dense) #follows the number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the model into a static graph for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1024, 1)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 32,866\n",
      "Trainable params: 32,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"553pt\" viewBox=\"0.00 0.00 310.00 553.00\" width=\"310pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-549 306,-549 306,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140326331144232 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140326331144232</title>\n",
       "<polygon fill=\"none\" points=\"19.5,-498.5 19.5,-544.5 282.5,-544.5 282.5,-498.5 19.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-517.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"152.5,-498.5 152.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"152.5,-521.5 210.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-498.5 210.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-529.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-521.5 282.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-506.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140326331144008 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140326331144008</title>\n",
       "<polygon fill=\"none\" points=\"10.5,-415.5 10.5,-461.5 291.5,-461.5 291.5,-415.5 10.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.5\" y=\"-434.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"138.5,-415.5 138.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"138.5,-438.5 196.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"196.5,-415.5 196.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-446.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"196.5,-438.5 291.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244\" y=\"-423.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140326331144232&#45;&gt;140326331144008 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140326331144232-&gt;140326331144008</title>\n",
       "<path d=\"M151,-498.3799C151,-490.1745 151,-480.7679 151,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-471.784 151,-461.784 147.5001,-471.784 154.5001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140325156216168 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140325156216168</title>\n",
       "<polygon fill=\"none\" points=\"2,-332.5 2,-378.5 300,-378.5 300,-332.5 2,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-351.8\">reshape_1: Reshape</text>\n",
       "<polyline fill=\"none\" points=\"132,-332.5 132,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"132,-355.5 190,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"190,-332.5 190,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245\" y=\"-363.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"190,-355.5 300,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245\" y=\"-340.3\">(None, 1024, 1)</text>\n",
       "</g>\n",
       "<!-- 140326331144008&#45;&gt;140325156216168 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140326331144008-&gt;140325156216168</title>\n",
       "<path d=\"M151,-415.3799C151,-407.1745 151,-397.7679 151,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-388.784 151,-378.784 147.5001,-388.784 154.5001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140325113417800 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140325113417800</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 302,-295.5 302,-249.5 0,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-268.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"134,-249.5 134,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134,-272.5 192,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"192,-249.5 192,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-280.3\">(None, 1024, 1)</text>\n",
       "<polyline fill=\"none\" points=\"192,-272.5 302,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-257.3\">(None, 1024, 1)</text>\n",
       "</g>\n",
       "<!-- 140325156216168&#45;&gt;140325113417800 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140325156216168-&gt;140325113417800</title>\n",
       "<path d=\"M151,-332.3799C151,-324.1745 151,-314.7679 151,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-305.784 151,-295.784 147.5001,-305.784 154.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140325113418248 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140325113418248</title>\n",
       "<polygon fill=\"none\" points=\"10.5,-166.5 10.5,-212.5 291.5,-212.5 291.5,-166.5 10.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-185.8\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"123.5,-166.5 123.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"123.5,-189.5 181.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-166.5 181.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-197.3\">(None, 1024, 1)</text>\n",
       "<polyline fill=\"none\" points=\"181.5,-189.5 291.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-174.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140325113417800&#45;&gt;140325113418248 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140325113417800-&gt;140325113418248</title>\n",
       "<path d=\"M151,-249.3799C151,-241.1745 151,-231.7679 151,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-222.784 151,-212.784 147.5001,-222.784 154.5001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140325113418360 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140325113418360</title>\n",
       "<polygon fill=\"none\" points=\"21,-83.5 21,-129.5 281,-129.5 281,-83.5 21,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.5\" y=\"-102.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"128,-83.5 128,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"128,-106.5 186,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186,-83.5 186,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-114.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"186,-106.5 281,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-91.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140325113418248&#45;&gt;140325113418360 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140325113418248-&gt;140325113418360</title>\n",
       "<path d=\"M151,-166.3799C151,-158.1745 151,-148.7679 151,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-139.784 151,-129.784 147.5001,-139.784 154.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140325113418416 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140325113418416</title>\n",
       "<polygon fill=\"none\" points=\"28.5,-.5 28.5,-46.5 273.5,-46.5 273.5,-.5 28.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-.5 135.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-23.5 193.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"193.5,-.5 193.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-31.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"193.5,-23.5 273.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140325113418360&#45;&gt;140325113418416 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140325113418360-&gt;140325113418416</title>\n",
       "<path d=\"M151,-83.3799C151,-75.1745 151,-65.7679 151,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"154.5001,-56.784 151,-46.784 147.5001,-56.784 154.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress:\n",
      "Train on 7464 samples, validate on 3198 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[{{node lambda_1/module_apply_default/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias/Read/ReadVariableOp/_43}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_130_l...VariableOp\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node lambda_1/module_apply_default/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel/Read/ReadVariableOp/_46}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_132_l...VariableOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lambda_1/module_apply_default/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel/Read/ReadVariableOp)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-625f541e317a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Progress:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n\u001b[0;32m----> 3\u001b[0;31m                                epochs=15, batch_size=64)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[{{node lambda_1/module_apply_default/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias/Read/ReadVariableOp/_43}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_130_l...VariableOp\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node lambda_1/module_apply_default/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel/Read/ReadVariableOp/_46}} = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_132_l...VariableOp\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lambda_1/module_apply_default/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel/Read/ReadVariableOp)]]"
     ]
    }
   ],
   "source": [
    "print(\"Training Progress:\")\n",
    "model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                               epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.plot(model_log.history['acc'])\n",
    "plt.plot(model_log.history['val_acc'])\n",
    "plt.title('Accuracy (Higher Better)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_log.history['loss'])\n",
    "plt.plot(model_log.history['val_loss'])\n",
    "plt.title('Loss (Lower Better)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "classes = [\"positive\", \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "print(classification_report(Y_test, y_pred_class, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark')\n",
    "def plot_confusion_matrix(cm, labels,\n",
    "                          normalize=True,\n",
    "                          title='Confusion Matrix (Validation Set)',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred_class)\n",
    "plot_confusion_matrix(cnf_matrix, labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
